{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEAREST NEIGHBORS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOAD THE DEPENDANCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import set_option\n",
    "from pandas.plotting import scatter_matrix\n",
    "import numpy as np\n",
    "from numpy import set_printoptions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, \"C:\\\\Users\\\\Crystal\\\\Desktop\\\\Programs\\\\my-modules-and-libraries\")\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score,recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### KNN Classifier\n",
    "\n",
    "def KNN(k,X_train,y_train,X_test,y_test):\n",
    "    \"\"\"KNN algorithm\"\"\"\n",
    "    \n",
    "    f1_scores=[]\n",
    "    accur=[]\n",
    "    preci=[]\n",
    "    recall=[]\n",
    "    for i in k:\n",
    "        \n",
    "        # Define KNN Model\n",
    "        classifier = KNeighborsClassifier(n_neighbors=i, weights='uniform', algorithm='auto',\n",
    "                                           leaf_size=30, p=2, metric='euclidean',metric_params=None)\n",
    "        # Fit Model\n",
    "        classifier.fit(X_train,y_train)\n",
    "\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        f1,a,p,r=metrics(y_test, y_pred)\n",
    "        \n",
    "        f1_scores.append(f1)\n",
    "        accur.append(a)\n",
    "        preci.append(p)\n",
    "        recall.append(r)\n",
    "        \n",
    "    print('\\n','f1_scores: ',f1_scores)\n",
    "    print('accuracy: ',accur)\n",
    "    \n",
    "    return f1_scores,accur,preci,recall\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Evaluate Model\n",
    "\n",
    "def metrics(y_test, y_pred):\n",
    "    \"\"\"Confusion matrix and associated metrics\"\"\"\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    tn,fp,fn,tp=confusion_matrix(y_test, y_pred).ravel()\n",
    "    precision=precision_score(y_test,y_pred)\n",
    "    recall=recall_score(y_test,y_pred)\n",
    "    f1=f1_score(y_test,y_pred)\n",
    "    accuracy=accuracy_score(y_test,y_pred)\n",
    "    print('Confusion matrix breakdown:',('tn:',tn,'fp:',fp,'fn:',fn,'tp:',tp),'\\n')\n",
    "    print('Confusion matrix:\\n', matrix)\n",
    "    print('Precision: When it predicts yes, how often is it correct?:',precision)\n",
    "    print('Recall.True Positive Rate: When it\\'s actually yes, how often does it predict yes?:',recall)\n",
    "    print('F1:score is the harmonic average of the precision and recall,:',f1)\n",
    "    print('Accuracy.Overall, how often is the classifier correct?: ',accuracy)\n",
    "    print('Misclassification Rate.Overall, how often is it wrong?: ',(1-accuracy))\n",
    "\n",
    "    return (f1,accuracy,precision,recall)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREPROCESSING: Replacing zeros where it is not a valid value for that feature.\n",
    "##### This done here by replacing the zero values with a NAN, then replacing the NAN with the average value for non-zero values in that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replacing_zeros(dataset,the_headers):\n",
    "    \"\"\"Function used to remove zeros from numeric features when 0 is not practical\"\"\"\n",
    "\n",
    "    for header in the_headers:\n",
    "        dataset[header]=dataset[header].replace(0,np.nan)\n",
    "        mean=int(dataset[header].mean(skipna=True))\n",
    "        dataset[header]=dataset[header].replace(np.nan,mean)\n",
    "        \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREPROCESSING: Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_the_dataset(dataset,input_headers,target_header):\n",
    "    \n",
    "#     X=dataset.iloc[:,0,8]\n",
    "#     X=dataset.iloc[:,[1,2,4,5,6,7]]\n",
    "#     y=dataset.iloc[:,8]\n",
    "    X=dataset[[input_headers]]\n",
    "    y=dataset[[target_header]]\n",
    "    \n",
    "    X.head()\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RETRIEVE THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location=r'C:\\Users\\Crystal\\Desktop\\Programs\\dataset_repo\\diabetes.csv'\n",
    "# location=r'C:\\Users\\Crystal\\Desktop\\Programs\\dataset_repo\\CDH_Train.csv'\n",
    "dataset=pd.read_csv(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREPROCESSING: Quick look at the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# X.hist(bins=50,figsize=(15,15))\n",
    "# X.plot(kind='hist',subplots=True,layout=(3,3),sharex=False, figsize=(15,15))\n",
    "\n",
    "headers=X.columns.tolist()\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(headers), figsize=(20, 10))\n",
    "print(headers)\n",
    "for i,head in enumerate(headers,0):\n",
    "    \n",
    "    axes[i].hist(x=X[head],bins=50,edgecolor='black')\n",
    "    axes[i].set(title=head)\n",
    "    axes[i].grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.plot(kind='density',subplots=True,layout=(3,3),sharex=False, figsize=(15,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREPROCESSING:Target Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_summary(dataset,target_header):\n",
    "    \"\"\"PREPROCESSING:Target Summary\"\"\"\n",
    "    print(dataset.groupby(target_header).size())\n",
    "    print((dataset.groupby(target_header).size()/len(y)*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREPROCESSING:Train - Test Split of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(X,y):\n",
    "    \"\"\"PREPROCESSING:Train - Test Split of the data\"\"\"\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.33,train_size=None,random_state=42,shuffle=True,)\n",
    "    X_train.head()\n",
    "    \n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREPROCESSING: Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scaling(X_train,X_test)\n",
    "sc_X=StandardScaler()\n",
    "X_train=sc_X.fit_transform(X=X_train,y=None)\n",
    "X_test=sc_X.fit_transform(X=X_test,y=None)\n",
    "\n",
    "print(sc_X.fit(X_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a value of k by taking the sqrt of the number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_suggest=round(math.sqrt(y_test.size))\n",
    "k=[3,5,7,9,11,13,15,17,19,21]\n",
    "k_suggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1,accur,precision,recall=KNN(k,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20, 10))\n",
    "axes[0,0].plot(k,f1,marker='o')\n",
    "axes[0,1].plot(k,accur,marker='o')\n",
    "axes[0,0].set(title='F1 Score')\n",
    "axes[0,1].set(title='Accuracy')\n",
    "axes[0,0].grid()\n",
    "axes[0,1].grid()\n",
    "\n",
    "axes[1,0].plot(k,precision,marker='o')\n",
    "axes[1,1].plot(k,recall,marker='o')\n",
    "axes[1,0].set(title='Precision')\n",
    "axes[1,1].set(title='Recall')\n",
    "axes[1,0].grid()\n",
    "axes[1,1].grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zero_not_accepted=['Glucose','BloodPressure','SkinThickness','BMI','Insulin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
