{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOAD THE DEPENDANCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import set_option\n",
    "from pandas.plotting import scatter_matrix\n",
    "import numpy as np\n",
    "from numpy import set_printoptions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, \"C:\\\\Users\\\\Crystal\\\\Desktop\\\\Programs\\\\my-modules-and-libraries\")\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score,recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### KNN Classifier\n",
    "\n",
    "def logistic_regression(X_train,y_train,X_test,y_test):\n",
    "    \"\"\"Logistic Regression algorithm\"\"\"\n",
    "    global classifier\n",
    "    \n",
    "    f1_scores=[]\n",
    "    accur=[]\n",
    "    preci=[]\n",
    "    recall=[]\n",
    "    \n",
    "        \n",
    "    # Define Logistic Regression Model\n",
    "    classifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001, \n",
    "                                    C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, \n",
    "                                    random_state=None, solver='liblinear', max_iter=100, multi_class='ovr', \n",
    "                                    verbose=0, warm_start=False, n_jobs=None)\n",
    "\n",
    "    # Fit Model\n",
    "    classifier.fit(X_train,y_train)\n",
    "\n",
    "    y_pred=classifier.predict(X_test)\n",
    "\n",
    "    y_prob=classifier.predict_proba(X_test)\n",
    "\n",
    "    y_prob=y_prob[:,1]\n",
    "\n",
    "    f1,a,p,r=metrics(y_test, y_pred)\n",
    "\n",
    "    f1_scores.append(f1)\n",
    "    accur.append(a)\n",
    "    preci.append(p)\n",
    "    recall.append(r)\n",
    "        \n",
    "    print('\\n','f1_scores: ',f1_scores)\n",
    "    print('accuracy: ',accur)\n",
    "    \n",
    "    return f1_scores,accur,preci,recall,y_pred,y_prob\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Evaluate Model\n",
    "\n",
    "def metrics(y_test, y_pred):\n",
    "    \"\"\"Confusion matrix and associated metrics\"\"\"\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    tn,fp,fn,tp=confusion_matrix(y_test, y_pred).ravel()\n",
    "    precision=precision_score(y_test,y_pred)\n",
    "    recall=recall_score(y_test,y_pred)\n",
    "    f1=f1_score(y_test,y_pred)\n",
    "    accuracy=accuracy_score(y_test,y_pred)\n",
    "    print('Confusion matrix breakdown:',('tn:',tn,'fp:',fp,'fn:',fn,'tp:',tp),'\\n')\n",
    "    print('Confusion matrix:\\n', matrix)\n",
    "    print('Precision: When it predicts yes, how often is it correct?:',precision)\n",
    "    print('Recall.True Positive Rate: When it\\'s actually yes, how often does it predict yes?:',recall)\n",
    "    print('F1:score is the harmonic average of the precision and recall,:',f1)\n",
    "    print('Accuracy.Overall, how often is the classifier correct?: ',accuracy)\n",
    "    print('Misclassification Rate.Overall, how often is it wrong?: ',(1-accuracy))\n",
    "\n",
    "    return (f1,accuracy,precision,recall)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREPROCESSING: Replacing zeros where it is not a valid value for that feature.\n",
    "##### This done here by replacing the zero values with a NAN, then replacing the NAN with the average value for non-zero values in that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replacing_zeros(dataset,the_headers):\n",
    "    \"\"\"Function used to remove zeros from numeric features when 0 is not practical\"\"\"\n",
    "\n",
    "    for header in the_headers:\n",
    "        dataset[header]=dataset[header].replace(0,np.nan)\n",
    "        mean=int(dataset[header].mean(skipna=True))\n",
    "        dataset[header]=dataset[header].replace(np.nan,mean)\n",
    "        \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREPROCESSING: Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_the_dataset(dataset,input_headers,target_header):\n",
    "    \n",
    "#     X=dataset.iloc[:,0,8]\n",
    "#     X=dataset.iloc[:,[1,2,4,5,6,7]]\n",
    "#     y=dataset.iloc[:,8]\n",
    "    X=dataset[input_headers]\n",
    "    y=dataset[target_header]\n",
    "    \n",
    "    X.head()\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREPROCESSING: Quick look at the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def quick_feature_view(X):\n",
    "    \n",
    "\n",
    "    # X.hist(bins=50,figsize=(15,15))\n",
    "    # X.plot(kind='hist',subplots=True,layout=(3,3),sharex=False, figsize=(15,15))\n",
    "\n",
    "    headers=X.columns.tolist()\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(headers), figsize=(20, 10))\n",
    "    print(headers)\n",
    "    for i,head in enumerate(headers,0):\n",
    "\n",
    "        axes[i].hist(x=X[head],bins=50,edgecolor='black')\n",
    "        axes[i].set(title=head)\n",
    "        axes[i].grid()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    X.plot(kind='density',subplots=True,layout=(3,3),sharex=False, figsize=(15,15))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREPROCESSING:Target Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def target_summary(dataset,target_header):\n",
    "    \"\"\"PREPROCESSING:Target Summary\"\"\"\n",
    "    print(dataset.groupby(target_header).size())\n",
    "    print((dataset.groupby(target_header).size()/len(y)*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREPROCESSING:Train - Test Split of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_the_train_test_data(X,y):\n",
    "    \n",
    "    \"\"\"PREPROCESSING:Train - Test Split of the data\"\"\"\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X, y,test_size=.30,random_state=42,shuffle=True)\n",
    "    X_train.head()\n",
    "    \n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREPROCESSING: Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_scaling(X_train,X_test):\n",
    "    sc_X=StandardScaler()\n",
    "    X_train=sc_X.fit_transform(X=X_train,y=None)\n",
    "    X_test=sc_X.fit_transform(X=X_test,y=None)\n",
    "\n",
    "    print(sc_X.fit(X_train))\n",
    "    print(X_train[0:5])\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_the_metrics(f1_scores,accur,preci,recall):\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20, 10),sharex='none')\n",
    "    axes[0,0].plot(k,f1_scores,marker='o')\n",
    "    axes[0,1].plot(k,accur,marker='o')\n",
    "    axes[0,0].set(title='F1 Score')\n",
    "    axes[0,1].set(title='Accuracy')\n",
    "    axes[0,0].set(xlabel='K value')\n",
    "    axes[0,1].set(xlabel='K value')\n",
    "#     axes[0,0].set(xlim=(3,21), ylim=(0,1))\n",
    "#     axes[0,1].set(xlim=(3,21), ylim=(0,1))\n",
    "    axes[0,0].set(xticks=range(3,23,2),yticks=np.arange(0,1.1,.1))\n",
    "    axes[0,1].set(xticks=range(3,23,2),yticks=np.arange(0,1.1,.1))\n",
    "    axes[0,0].grid()\n",
    "    axes[0,1].grid()\n",
    "\n",
    "    axes[1,0].plot(k,preci,marker='o')\n",
    "    axes[1,1].plot(k,recall,marker='o')\n",
    "    axes[1,0].set(title='Precision')\n",
    "    axes[1,1].set(title='Recall')\n",
    "    axes[1,0].set(xlabel='K value')\n",
    "    axes[1,1].set(xlabel='K value')\n",
    "#     axes[1,0].set(xlim=(3,21), ylim=(0,1))\n",
    "#     axes[1,1].set(xlim=(3,21), ylim=(0,1))\n",
    "    axes[1,0].set(xticks=range(3,23,2),yticks=np.arange(0,1.1,.1))\n",
    "    axes[1,1].set(xticks=range(3,23,2),yticks=np.arange(0,1.1,.1))\n",
    "    axes[1,0].grid()\n",
    "    axes[1,1].grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def box_plot_the_metrics(f1_scores,accur,preci,recall):\n",
    "    \"\"\"Box plots for the classification metrics over a range of parameter adjustments\"\"\"\n",
    "    \n",
    "    f=np.asarray(f1_scores)\n",
    "    a=np.asarray(accur)\n",
    "    p=np.asarray(preci)\n",
    "    r=np.asarray(recall)\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(20, 10))\n",
    "    axes.boxplot([f,a,p,r])\n",
    "    axes.set_xticklabels(['f1_score','accuracy','precision','recall'])\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_of_data_space(data,labels,input_headers):\n",
    "    \n",
    "    \n",
    "    xx_1=pd.DataFrame(data[:,0]) \n",
    "    xx_2=pd.DataFrame(data[:,1]) \n",
    "    y=pd.DataFrame(labels)\n",
    "\n",
    "#     print(xx_1.head(),'\\n',xx_2.head(),'\\n',y.head())\n",
    "#     print(list(xx_1[y==0]))\n",
    "#     print(list(xx_1[y==1]))\n",
    "    plt.figure(figsize=(15,10)) \n",
    "    b=plt.scatter(xx_1[y==0],xx_2[y==0],color='b') \n",
    "    r=plt.scatter(xx_1[y==1],xx_2[y==1],color='r')\n",
    "\n",
    "#     plt.scatter(data[:,0],data[:,1],s=40,c=labels,cmap=plt.cm.Spectral)\n",
    "#     plt.scatter(x_test[:,0],x_test[:,1],color='black')\n",
    "\n",
    "    plt.xlabel(input_headers[0])\n",
    "    plt.ylabel(input_headers[1])\n",
    "#     plt.xlim(xx_1.min(),xx_1.max())\n",
    "#     plt.ylim(xx_2.min(),xx_2.max())\n",
    "    plt.grid()\n",
    "    plt.legend((b,r),tuple(np.unique(labels)))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def boundary_decision_plot(X,y,X_train,y_train,x_test,y_pred,y_prob):\n",
    "    \n",
    "    X_unscaled=X.values\n",
    "    X_scaled, dummy=feature_scaling(X_unscaled,X_test=1)\n",
    "    xx_1=pd.DataFrame(X_train[:,0]) \n",
    "    xx_2=pd.DataFrame(X_train[:,1]) \n",
    "    y=pd.DataFrame(y_train.values)\n",
    "    \n",
    "#     print(y_train[0:5])\n",
    "#     print(X_train[0:5])\n",
    "\n",
    "    xx_test_1=pd.DataFrame(x_test[:,0]) \n",
    "    xx_test_2=pd.DataFrame(x_test[:,1])\n",
    "\n",
    "    y_predict=pd.DataFrame(y_pred) \n",
    "    y_prob=pd.DataFrame(y_prob) \n",
    "\n",
    "    cmap_light = ListedColormap(['#FFAAAA','#AAAAFF'])\n",
    "\n",
    "#     cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "    cmap_bold = ListedColormap(['#FF0000','#0000FF'])\n",
    "\n",
    "    h=.02\n",
    "\n",
    "#     Plot the decision boundary. For that, we will assign a color to each point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "#     x1=X_train[:,0] \n",
    "    x1=X_scaled[:,0]\n",
    "    x2=X_scaled[:,1] \n",
    "    x_min,x_max = x1.min()-1,x1.max()+1 \n",
    "    y_min,y_max = x2.min()-1,x2.max()+1 \n",
    "    xx,yy = np.meshgrid(np.arange(x_min,x_max,h),np.arange(y_min,y_max,h))\n",
    "\n",
    "\n",
    "    the_predict=classifier.predict(np.c_[xx.ravel(),yy.ravel()])\n",
    "\n",
    "#     Put the result into a color plot\n",
    "    Z = the_predict.reshape(xx.shape) \n",
    "    plt.figure(figsize=(15,15)) \n",
    "    plt.xlim(xx.min(),xx.max()) \n",
    "    plt.ylim(yy.min(),yy.max())\n",
    "\n",
    "    plt.pcolormesh(xx,yy,Z,cmap=cmap_light)\n",
    "\n",
    "#     plt.scatter(xx_1[y==0],xx_2[y==0],color='b',marker='o') \n",
    "#     plt.scatter(xx_1[y==1],xx_2[y==1],color='r',marker='o')\n",
    "    \n",
    "\n",
    "#     plt.scatter(X_train[:,0],X_train[:,1],s=40,c=y_train,cmap=plt.cm.Spectral)\n",
    "    cm=plt.cm.get_cmap('RdYlBu_r')\n",
    "\n",
    "#     plt.scatter(xx_test_1[y_predict==0],xx_test_2[y_predict==0],cmap=cm,vmin=0,vmax=1,c=y_predict,marker='D') \n",
    "#     plt.scatter(xx_test_1[y_predict==1],xx_test_2[y_predict==1],cmap=cm,vmin=0,vmax=1,c=y_predict,marker='D') \n",
    "    plt.scatter(xx_test_1[y_predict==0],xx_test_2[y_predict==0],cmap=cm,vmin=0,vmax=1,c=y_prob,marker='D') \n",
    "    plt.scatter(xx_test_1[y_predict==1],xx_test_2[y_predict==1],cmap=cm,vmin=0,vmax=1,c=y_prob,marker='D') \n",
    "    plt.colorbar()\n",
    "\n",
    "\n",
    "    plt.grid() \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_results(f1_scores,accur,preci,recall):\n",
    "    \n",
    "    f=np.asarray(f1_scores)\n",
    "    a=np.asarray(accur)\n",
    "    p=np.asarray(preci)\n",
    "    r=np.asarray(recall)\n",
    "    \n",
    "    \n",
    "    results=f\"\"\"\\n\n",
    "    The max F1 SCORE is {f.max()} \n",
    "    The max ACCURACY is {a.max()} \n",
    "    The max PRECISION is {p.max()} \n",
    "    The max RECALL is {r.max()} \n",
    "    \"\"\"\n",
    "    \n",
    "    print(results)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN PROGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    global classifier\n",
    "    \n",
    "#     RETRIEVE THE DATASET\n",
    "    \n",
    "    location=r'C:/Users/Crystal/Desktop/Programs/dataset_repo/titan/titantic_1.csv'\n",
    "#     location=r'C:\\Users\\Crystal\\Desktop\\Programs\\dataset_repo\\diabetes.csv'\n",
    "#     location=r'C:\\Users\\Crystal\\Desktop\\Programs\\dataset_repo\\CDH_Train.csv'\n",
    "    dataset=pd.read_csv(location)\n",
    "\n",
    "    print(dataset.info())\n",
    "    dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you need to replace any zeros in the dataset?y\n"
     ]
    }
   ],
   "source": [
    "    # Replace zeros with the mean where needed.\n",
    "    rz=input('Do you need to replace any zeros in the dataset?')\n",
    "    if (rz.lower()=='y'):\n",
    "        the_headers=['Age']\n",
    "        dataset=replacing_zeros(dataset,the_headers)\n",
    "        dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting inputs and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Parch    Fare  SibSp   Age  Pclass\n",
      "0      0   7.250      1  22.0       3\n",
      "1      0  71.283      1  38.0       1\n",
      "2      0   7.925      0  26.0       3\n",
      "3      0  53.100      1  35.0       1\n",
      "4      0   8.050      0  35.0       3\n"
     ]
    }
   ],
   "source": [
    "    #Selecting inputs and targets\n",
    "    \n",
    "    target_header=['Survived']\n",
    "    input_headers=['Parch','Fare','SibSp','Age','Pclass']\n",
    "    \n",
    "    X,y=split_the_dataset(dataset,input_headers,target_header)\n",
    "    if (X.values.shape[1]==2):\n",
    "        plot_of_data_space(X.values,y.values,input_headers)\n",
    "        \n",
    "    print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    #Splitting the Train-Test data\n",
    "    X_train,X_test,y_train,y_test=split_the_train_test_data(X,y)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[[ 1.99885349  0.98099249 -0.47416141 -1.93637586 -1.63788124]\n",
      " [-0.47932706 -0.4696298  -0.47416141 -0.01577421  0.80326712]\n",
      " [ 0.75976322 -0.40614228  0.34868694 -2.16684805  0.80326712]\n",
      " [ 1.99885349 -0.0802318   0.34868694  0.52199425 -0.41730706]\n",
      " [ 0.75976322 -0.10965142  0.34868694  1.05976271 -0.41730706]]\n"
     ]
    }
   ],
   "source": [
    "    #Scale the data    \n",
    "    X_train, X_test=feature_scaling(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix breakdown: ('tn:', 145, 'fp:', 12, 'fn:', 60, 'tp:', 51) \n",
      "\n",
      "Confusion matrix:\n",
      " [[145  12]\n",
      " [ 60  51]]\n",
      "Precision: When it predicts yes, how often is it correct?: 0.8095238095238095\n",
      "Recall.True Positive Rate: When it's actually yes, how often does it predict yes?: 0.4594594594594595\n",
      "F1:score is the harmonic average of the precision and recall,: 0.5862068965517242\n",
      "Accuracy.Overall, how often is the classifier correct?:  0.7313432835820896\n",
      "Misclassification Rate.Overall, how often is it wrong?:  0.26865671641791045\n",
      "\n",
      " f1_scores:  [0.5862068965517242]\n",
      "accuracy:  [0.7313432835820896]\n",
      "[0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1\n",
      " 0 1 1 1 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 0 0\n",
      " 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 1]\n",
      "[0.21117491 0.38521967 0.29333542 0.68269364 0.25982045 0.70201995\n",
      " 0.23208975 0.18580968 0.32310066 0.78469177 0.48423872 0.15158184\n",
      " 0.11345508 0.22539538 0.34753138 0.77442739 0.43985808 0.23216471\n",
      " 0.42225326 0.49394687 0.26502621 0.57378109 0.22431361 0.29477201\n",
      " 0.23855546 0.2423132  0.52313599 0.38837626 0.28310318 0.21989107\n",
      " 0.3006424  0.27878887 0.62131447 0.23190005 0.30825974 0.18440355\n",
      " 0.63549365 0.23208975 0.61339284 0.2322283  0.36053988 0.16846641\n",
      " 0.2323745  0.23208975 0.18417937 0.42825234 0.30093573 0.27333287\n",
      " 0.26414989 0.595162   0.299629   0.46498987 0.28249825 0.8425205\n",
      " 0.07856111 0.83375394 0.37692883 0.75881545 0.36536168 0.30062337\n",
      " 0.28593878 0.61022081 0.33721775 0.61532059 0.23208975 0.20077921\n",
      " 0.5546449  0.23220836 0.28116324 0.38784321 0.40844771 0.85726003\n",
      " 0.64494341 0.56504554 0.27188564 0.14217561 0.22282508 0.78773987\n",
      " 0.33176473 0.25312878 0.12792079 0.40199845 0.62241888 0.23207836\n",
      " 0.38840968 0.29293435 0.61495534 0.64557117 0.50383624 0.2316157\n",
      " 0.51114077 0.18495086 0.3495275  0.23206982 0.2322283  0.23851432\n",
      " 0.38802879 0.14711614 0.34753138 0.24499893 0.31859731 0.19610879\n",
      " 0.6839249  0.17995493 0.22310177 0.18968746 0.31145526 0.47599843\n",
      " 0.22751687 0.52748867 0.55287725 0.2889664  0.6010456  0.55616051\n",
      " 0.81940917 0.2954597  0.27683254 0.34738051 0.44675181 0.19562221\n",
      " 0.32336382 0.65303333 0.30054244 0.76163266 0.25757745 0.56516271\n",
      " 0.44193633 0.71689361 0.17406633 0.28623777 0.23221216 0.21117491\n",
      " 0.38863794 0.41879512 0.38591421 0.25636347 0.7154498  0.23211347\n",
      " 0.16048775 0.24001392 0.28665451 0.22475522 0.41370173 0.2704984\n",
      " 0.4355691  0.35046213 0.39675856 0.15475162 0.6716108  0.15615828\n",
      " 0.23300371 0.26461165 0.30797149 0.18160914 0.2323745  0.23142627\n",
      " 0.28149612 0.2321258  0.27749082 0.19435373 0.26776725 0.61610782\n",
      " 0.32401801 0.59216347 0.23276215 0.40882587 0.45357743 0.55269564\n",
      " 0.27894517 0.19604586 0.75305064 0.61606945 0.55629191 0.3509659\n",
      " 0.3147427  0.23159202 0.35246913 0.50617266 0.39381821 0.47587253\n",
      " 0.45687789 0.21398392 0.18440631 0.20137881 0.88697185 0.47766761\n",
      " 0.33143341 0.2322283  0.62731261 0.30136073 0.17997313 0.37091153\n",
      " 0.23601446 0.23375423 0.30622635 0.55074345 0.773216   0.36363958\n",
      " 0.65943042 0.17458646 0.08870937 0.22673378 0.71709912 0.08455802\n",
      " 0.29256798 0.34327503 0.23373802 0.68960551 0.23851485 0.12640052\n",
      " 0.88058555 0.22541862 0.56807001 0.23206603 0.11345508 0.24412934\n",
      " 0.42215349 0.52999588 0.51524673 0.2316157  0.2322283  0.44816909\n",
      " 0.28807786 0.62106895 0.2573739  0.56708423 0.27854383 0.90019564\n",
      " 0.36932695 0.25158855 0.28633457 0.84386314 0.23208975 0.23159581\n",
      " 0.23295615 0.27881563 0.40072296 0.31029764 0.74761796 0.2023642\n",
      " 0.29187923 0.23724188 0.23159202 0.29414935 0.19831247 0.24010943\n",
      " 0.2323745  0.2719299  0.27825401 0.42203305 0.23031231 0.47296905\n",
      " 0.23208975 0.27823156 0.38048455 0.24409315 0.27911009 0.395828\n",
      " 0.34451977 0.32940647 0.79972261 0.44122701 0.31636654 0.24575399\n",
      " 0.58217855 0.3116427  0.31651009 0.62438755]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Programming\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Public\\Programming\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = None.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    }
   ],
   "source": [
    "    #Call the Logistic Regression function\n",
    "    f1_scores,accur,preci,recall,y_pred,y_prob=logistic_regression(X_train,y_train,X_test,y_test)\n",
    "    print(y_pred)\n",
    "    print(y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    #Plot the metrics\n",
    "#     plot_the_metrics(f1_scores,accur,preci,recall)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIsAAAJDCAYAAACL5JSNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwPD/AQct56pVPs86AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbb34eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    #Box plot of the metrics\n",
    "    box_plot_the_metrics(f1_scores,accur,preci,recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    The max F1 SCORE is 0.5862068965517242 \n",
      "    The max ACCURACY is 0.7313432835820896 \n",
      "    The max PRECISION is 0.8095238095238095 \n",
      "    The max RECALL is 0.4594594594594595 \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "    max_results(f1_scores,accur,preci,recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    #Plot the decision boundaries (for input vectors only)\n",
    "    \n",
    "    if (X.values.shape[1]==2):\n",
    "        boundary_decision_plot(X,y,X_train,y_train,X_test,y_pred,y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
